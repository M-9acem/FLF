{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1da38739",
   "metadata": {},
   "source": [
    "# Decentralized Federated Learning (P2P) Analysis\n",
    "\n",
    "This notebook analyzes experiments run in **decentralized mode** using peer-to-peer gossip protocols.\n",
    "\n",
    "**Features:**\n",
    "- P2P network topology analysis\n",
    "- Gossip propagation patterns\n",
    "- Mixing matrix effectiveness\n",
    "- Per-client local model performance\n",
    "- Network convergence without central server\n",
    "- Communication efficiency metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9b401b",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa41f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10461736",
   "metadata": {},
   "source": [
    "## 2. Load Experiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d4fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify experiment directory\n",
    "logs_base = Path('logs')\n",
    "\n",
    "# Auto-detect latest decentralized experiment or specify manually\n",
    "# Common patterns: metropolis_hastings, max_degree, jaccard, matcha\n",
    "decentralized_dirs = [d for d in logs_base.glob('*') if d.is_dir() and \n",
    "                      any(x in d.name.lower() for x in ['metropolis', 'max_degree', 'jaccard', 'matcha', 'p2p'])]\n",
    "\n",
    "if decentralized_dirs:\n",
    "    # Get most recent\n",
    "    experiment_dir = max(decentralized_dirs, key=lambda p: p.stat().st_mtime)\n",
    "    # Or use specific subdirectory with timestamp\n",
    "    subdirs = sorted([d for d in experiment_dir.iterdir() if d.is_dir()], reverse=True)\n",
    "    if subdirs:\n",
    "        experiment_dir = subdirs[0]\n",
    "else:\n",
    "    # Manually specify\n",
    "    experiment_dir = logs_base / 'metropolis_hastings_comparison' / '2026-02-05_12-00-00'\n",
    "\n",
    "print(f\"Analyzing experiment: {experiment_dir}\")\n",
    "print(f\"Experiment path: {experiment_dir.absolute()}\")\n",
    "\n",
    "# Create plots directory\n",
    "plots_dir = experiment_dir / 'plots'\n",
    "plots_dir.mkdir(exist_ok=True)\n",
    "print(f\"Plots will be saved to: {plots_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99024b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_file = experiment_dir / 'config.json'\n",
    "if config_file.exists():\n",
    "    with open(config_file, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    print(\"\\nExperiment Configuration:\")\n",
    "    for key, value in config.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"Warning: config.json not found\")\n",
    "    config = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e25ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV files\n",
    "per_client_file = experiment_dir / 'per_client_metrics.csv'\n",
    "per_class_file = experiment_dir / 'per_class_metrics.csv'\n",
    "gradient_file = experiment_dir / 'gradient_metrics.csv'\n",
    "propagation_file = experiment_dir / 'propagation_metrics.csv'  # P2P specific!\n",
    "convergence_file = experiment_dir / 'convergence_metrics.csv'\n",
    "data_dist_file = experiment_dir / 'data_distribution.csv'\n",
    "comm_eff_file = experiment_dir / 'communication_efficiency.csv'\n",
    "round_summary_file = experiment_dir / 'round_summary.csv'\n",
    "\n",
    "# Load available files\n",
    "dfs = {}\n",
    "if per_client_file.exists():\n",
    "    dfs['per_client'] = pd.read_csv(per_client_file)\n",
    "    print(f\"âœ“ Loaded per_client_metrics: {len(dfs['per_client'])} records\")\n",
    "\n",
    "if per_class_file.exists():\n",
    "    dfs['per_class'] = pd.read_csv(per_class_file)\n",
    "    print(f\"âœ“ Loaded per_class_metrics: {len(dfs['per_class'])} records\")\n",
    "\n",
    "if gradient_file.exists():\n",
    "    dfs['gradient'] = pd.read_csv(gradient_file)\n",
    "    print(f\"âœ“ Loaded gradient_metrics: {len(dfs['gradient'])} records\")\n",
    "\n",
    "if propagation_file.exists():\n",
    "    dfs['propagation'] = pd.read_csv(propagation_file)\n",
    "    print(f\"âœ“ Loaded propagation_metrics: {len(dfs['propagation'])} records\")\n",
    "\n",
    "if convergence_file.exists():\n",
    "    dfs['convergence'] = pd.read_csv(convergence_file)\n",
    "    print(f\"âœ“ Loaded convergence_metrics: {len(dfs['convergence'])} records\")\n",
    "\n",
    "if data_dist_file.exists():\n",
    "    dfs['data_dist'] = pd.read_csv(data_dist_file)\n",
    "    print(f\"âœ“ Loaded data_distribution: {len(dfs['data_dist'])} records\")\n",
    "\n",
    "if comm_eff_file.exists():\n",
    "    dfs['comm_eff'] = pd.read_csv(comm_eff_file)\n",
    "    print(f\"âœ“ Loaded communication_efficiency: {len(dfs['comm_eff'])} records\")\n",
    "\n",
    "if round_summary_file.exists():\n",
    "    dfs['round_summary'] = pd.read_csv(round_summary_file)\n",
    "    print(f\"âœ“ Loaded round_summary: {len(dfs['round_summary'])} records\")\n",
    "\n",
    "print(f\"\\nTotal files loaded: {len(dfs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89edb04",
   "metadata": {},
   "source": [
    "## 3. Network-Wide Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7e4cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'round_summary' in dfs:\n",
    "    df_summary = dfs['round_summary']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Average accuracy across network\n",
    "    axes[0].plot(df_summary['round'], df_summary['avg_test_accuracy'], \n",
    "                marker='o', linewidth=2, label='Average Accuracy', color='blue')\n",
    "    axes[0].fill_between(df_summary['round'], \n",
    "                          df_summary['min_test_accuracy'], \n",
    "                          df_summary['max_test_accuracy'], \n",
    "                          alpha=0.2, label='Min-Max Range')\n",
    "    axes[0].set_xlabel('Round')\n",
    "    axes[0].set_ylabel('Test Accuracy (%)')\n",
    "    axes[0].set_title('Network-Wide Test Accuracy')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Average loss across network\n",
    "    axes[1].plot(df_summary['round'], df_summary['avg_test_loss'], \n",
    "                marker='o', linewidth=2, label='Average Loss', color='red')\n",
    "    axes[1].fill_between(df_summary['round'], \n",
    "                          df_summary['min_test_loss'], \n",
    "                          df_summary['max_test_loss'], \n",
    "                          alpha=0.2, label='Min-Max Range')\n",
    "    axes[1].set_xlabel('Round')\n",
    "    axes[1].set_ylabel('Test Loss')\n",
    "    axes[1].set_title('Network-Wide Test Loss')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / 'network_performance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nFinal Network Performance:\")\n",
    "    print(f\"  Average Test Accuracy: {df_summary['avg_test_accuracy'].iloc[-1]:.2f}%\")\n",
    "    print(f\"  Average Test Loss: {df_summary['avg_test_loss'].iloc[-1]:.4f}\")\n",
    "    print(f\"  Best Average Accuracy: {df_summary['avg_test_accuracy'].max():.2f}% (Round {df_summary.loc[df_summary['avg_test_accuracy'].idxmax(), 'round']:.0f})\")\n",
    "    print(f\"  Accuracy Range: [{df_summary['min_test_accuracy'].iloc[-1]:.2f}%, {df_summary['max_test_accuracy'].iloc[-1]:.2f}%]\")\n",
    "else:\n",
    "    print(\"Round summary not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3e0f0b",
   "metadata": {},
   "source": [
    "## 4. P2P Gossip Propagation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44945e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'propagation' in dfs:\n",
    "    df_prop = dfs['propagation']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Messages sent per round\n",
    "    msg_per_round = df_prop.groupby('round')['messages_sent'].sum()\n",
    "    axes[0, 0].bar(msg_per_round.index, msg_per_round.values, alpha=0.7, color='steelblue')\n",
    "    axes[0, 0].set_xlabel('Round')\n",
    "    axes[0, 0].set_ylabel('Total Messages Sent')\n",
    "    axes[0, 0].set_title('Gossip Messages per Round')\n",
    "    axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 2. Messages per client\n",
    "    final_round = df_prop['round'].max()\n",
    "    final_prop = df_prop[df_prop['round'] == final_round]\n",
    "    axes[0, 1].bar(final_prop['client_id'], final_prop['messages_sent'], \n",
    "                   alpha=0.7, color='coral')\n",
    "    axes[0, 1].axhline(final_prop['messages_sent'].mean(), \n",
    "                      color='red', linestyle='--', linewidth=2, \n",
    "                      label=f\"Mean: {final_prop['messages_sent'].mean():.1f}\")\n",
    "    axes[0, 1].set_xlabel('Client ID')\n",
    "    axes[0, 1].set_ylabel('Messages Sent')\n",
    "    axes[0, 1].set_title(f'Messages Sent by Client (Round {final_round})')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 3. Gossip rounds per communication round\n",
    "    gossip_rounds = df_prop.groupby('round')['gossip_rounds'].first()\n",
    "    axes[1, 0].plot(gossip_rounds.index, gossip_rounds.values, \n",
    "                   marker='o', linewidth=2, color='green')\n",
    "    axes[1, 0].set_xlabel('Round')\n",
    "    axes[1, 0].set_ylabel('Gossip Rounds')\n",
    "    axes[1, 0].set_title('Gossip Iterations per Round')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Active neighbors over rounds\n",
    "    for client_id in df_prop['client_id'].unique():\n",
    "        client_prop = df_prop[df_prop['client_id'] == client_id]\n",
    "        axes[1, 1].plot(client_prop['round'], client_prop['active_neighbors'], \n",
    "                       marker='o', alpha=0.6, label=f'Client {client_id}')\n",
    "    axes[1, 1].set_xlabel('Round')\n",
    "    axes[1, 1].set_ylabel('Active Neighbors')\n",
    "    axes[1, 1].set_title('Active Neighbor Connections')\n",
    "    axes[1, 1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / 'propagation_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nGossip Propagation Statistics:\")\n",
    "    print(f\"  Total Messages Sent: {df_prop['messages_sent'].sum()}\")\n",
    "    print(f\"  Average Messages per Round: {msg_per_round.mean():.1f}\")\n",
    "    print(f\"  Average Active Neighbors: {df_prop['active_neighbors'].mean():.2f}\")\n",
    "    print(f\"  Average Gossip Rounds: {gossip_rounds.mean():.2f}\")\n",
    "else:\n",
    "    print(\"Propagation metrics not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d6813",
   "metadata": {},
   "source": [
    "## 5. Mixing Matrix and Consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78836f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'propagation' in dfs:\n",
    "    df_prop = dfs['propagation']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Consensus error evolution\n",
    "    consensus_per_round = df_prop.groupby('round')['consensus_error'].mean()\n",
    "    axes[0, 0].semilogy(consensus_per_round.index, consensus_per_round.values, \n",
    "                        marker='o', linewidth=2, color='purple')\n",
    "    axes[0, 0].set_xlabel('Round')\n",
    "    axes[0, 0].set_ylabel('Consensus Error (log scale)')\n",
    "    axes[0, 0].set_title('Network Consensus Error Evolution')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Model divergence\n",
    "    divergence_per_round = df_prop.groupby('round')['model_divergence'].mean()\n",
    "    axes[0, 1].plot(divergence_per_round.index, divergence_per_round.values, \n",
    "                   marker='o', linewidth=2, color='red')\n",
    "    axes[0, 1].set_xlabel('Round')\n",
    "    axes[0, 1].set_ylabel('Model Divergence')\n",
    "    axes[0, 1].set_title('Average Model Divergence')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Spectral gap (mixing matrix quality indicator)\n",
    "    spectral_gap = df_prop.groupby('round')['spectral_gap'].first()\n",
    "    axes[1, 0].plot(spectral_gap.index, spectral_gap.values, \n",
    "                   marker='o', linewidth=2, color='teal')\n",
    "    axes[1, 0].axhline(spectral_gap.mean(), color='red', linestyle='--', \n",
    "                      linewidth=2, label=f'Mean: {spectral_gap.mean():.4f}')\n",
    "    axes[1, 0].set_xlabel('Round')\n",
    "    axes[1, 0].set_ylabel('Spectral Gap')\n",
    "    axes[1, 0].set_title('Mixing Matrix Spectral Gap (Higher = Better)')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Consensus error per client (final round)\n",
    "    final_round = df_prop['round'].max()\n",
    "    final_consensus = df_prop[df_prop['round'] == final_round]\n",
    "    axes[1, 1].bar(final_consensus['client_id'], final_consensus['consensus_error'], \n",
    "                   alpha=0.7, color='orange')\n",
    "    axes[1, 1].set_xlabel('Client ID')\n",
    "    axes[1, 1].set_ylabel('Consensus Error')\n",
    "    axes[1, 1].set_title(f'Consensus Error by Client (Round {final_round})')\n",
    "    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / 'consensus_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nConsensus Statistics:\")\n",
    "    print(f\"  Final Consensus Error: {consensus_per_round.iloc[-1]:.6f}\")\n",
    "    print(f\"  Final Model Divergence: {divergence_per_round.iloc[-1]:.6f}\")\n",
    "    print(f\"  Average Spectral Gap: {spectral_gap.mean():.4f}\")\n",
    "    print(f\"  Convergence Rate: {(consensus_per_round.iloc[0] - consensus_per_round.iloc[-1]) / len(consensus_per_round):.6f} per round\")\n",
    "else:\n",
    "    print(\"Propagation metrics not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111ff7dc",
   "metadata": {},
   "source": [
    "## 6. Per-Client Local Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7556002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'per_client' in dfs:\n",
    "    df_client = dfs['per_client']\n",
    "    \n",
    "    # Get final round data\n",
    "    final_round = df_client['round'].max()\n",
    "    final_data = df_client[df_client['round'] == final_round]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Client accuracy evolution\n",
    "    for client_id in df_client['client_id'].unique():\n",
    "        client_data = df_client[df_client['client_id'] == client_id]\n",
    "        # Get last epoch of each round\n",
    "        last_epochs = client_data.groupby('round').last()\n",
    "        axes[0, 0].plot(last_epochs.index, last_epochs['test_accuracy'], \n",
    "                       marker='o', alpha=0.7, label=f'Client {client_id}')\n",
    "    axes[0, 0].set_xlabel('Round')\n",
    "    axes[0, 0].set_ylabel('Test Accuracy (%)')\n",
    "    axes[0, 0].set_title('Per-Client Test Accuracy Evolution')\n",
    "    axes[0, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Client loss evolution\n",
    "    for client_id in df_client['client_id'].unique():\n",
    "        client_data = df_client[df_client['client_id'] == client_id]\n",
    "        last_epochs = client_data.groupby('round').last()\n",
    "        axes[0, 1].plot(last_epochs.index, last_epochs['test_loss'], \n",
    "                       marker='o', alpha=0.7, label=f'Client {client_id}')\n",
    "    axes[0, 1].set_xlabel('Round')\n",
    "    axes[0, 1].set_ylabel('Test Loss')\n",
    "    axes[0, 1].set_title('Per-Client Test Loss Evolution')\n",
    "    axes[0, 1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Final round accuracy comparison\n",
    "    final_acc = final_data.groupby('client_id')['test_accuracy'].last()\n",
    "    axes[1, 0].bar(final_acc.index, final_acc.values, alpha=0.7, color='steelblue')\n",
    "    axes[1, 0].axhline(final_acc.mean(), color='red', linestyle='--', \n",
    "                      linewidth=2, label=f'Mean: {final_acc.mean():.2f}%')\n",
    "    axes[1, 0].set_xlabel('Client ID')\n",
    "    axes[1, 0].set_ylabel('Test Accuracy (%)')\n",
    "    axes[1, 0].set_title(f'Final Test Accuracy by Client (Round {final_round})')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 4. Accuracy distribution and fairness\n",
    "    axes[1, 1].hist(final_acc.values, bins=15, alpha=0.7, color='green', edgecolor='black')\n",
    "    axes[1, 1].axvline(final_acc.mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    axes[1, 1].axvline(final_acc.median(), color='blue', linestyle='--', linewidth=2, label='Median')\n",
    "    axes[1, 1].set_xlabel('Test Accuracy (%)')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].set_title('Client Accuracy Distribution')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / 'per_client_local_performance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nClient Local Model Statistics (Final Round):\")\n",
    "    print(f\"  Mean Accuracy: {final_acc.mean():.2f}%\")\n",
    "    print(f\"  Std Dev: {final_acc.std():.2f}%\")\n",
    "    print(f\"  Min Accuracy: {final_acc.min():.2f}% (Client {final_acc.idxmin()})\")\n",
    "    print(f\"  Max Accuracy: {final_acc.max():.2f}% (Client {final_acc.idxmax()})\")\n",
    "    print(f\"  Fairness Gap: {final_acc.max() - final_acc.min():.2f}%\")\n",
    "else:\n",
    "    print(\"Per-client metrics not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a734c14",
   "metadata": {},
   "source": [
    "## 7. Communication Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1864cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'comm_eff' in dfs:\n",
    "    df_comm = dfs['comm_eff']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Bytes sent per round\n",
    "    bytes_per_round = df_comm.groupby('round')['bytes_sent'].sum()\n",
    "    axes[0, 0].plot(bytes_per_round.index, bytes_per_round.values / 1e6, \n",
    "                   marker='o', linewidth=2, color='blue')\n",
    "    axes[0, 0].set_xlabel('Round')\n",
    "    axes[0, 0].set_ylabel('Total Bytes Sent (MB)')\n",
    "    axes[0, 0].set_title('Communication Volume per Round')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Bytes received per round\n",
    "    bytes_recv_per_round = df_comm.groupby('round')['bytes_received'].sum()\n",
    "    axes[0, 1].plot(bytes_recv_per_round.index, bytes_recv_per_round.values / 1e6, \n",
    "                   marker='o', linewidth=2, color='green')\n",
    "    axes[0, 1].set_xlabel('Round')\n",
    "    axes[0, 1].set_ylabel('Total Bytes Received (MB)')\n",
    "    axes[0, 1].set_title('Data Reception per Round')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Communication overhead per client\n",
    "    final_round = df_comm['round'].max()\n",
    "    final_comm = df_comm[df_comm['round'] == final_round]\n",
    "    axes[1, 0].bar(final_comm['client_id'], final_comm['bytes_sent'] / 1e6, \n",
    "                   alpha=0.7, color='coral', label='Sent')\n",
    "    axes[1, 0].bar(final_comm['client_id'], final_comm['bytes_received'] / 1e6, \n",
    "                   alpha=0.7, color='lightgreen', label='Received')\n",
    "    axes[1, 0].set_xlabel('Client ID')\n",
    "    axes[1, 0].set_ylabel('Data (MB)')\n",
    "    axes[1, 0].set_title(f'Communication Volume by Client (Round {final_round})')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 4. Communication rounds\n",
    "    comm_rounds = df_comm.groupby('round')['communication_rounds'].first()\n",
    "    axes[1, 1].plot(comm_rounds.index, comm_rounds.values, \n",
    "                   marker='o', linewidth=2, color='purple')\n",
    "    axes[1, 1].set_xlabel('Round')\n",
    "    axes[1, 1].set_ylabel('Communication Rounds')\n",
    "    axes[1, 1].set_title('Communication Rounds per Training Round')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / 'communication_efficiency.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nCommunication Efficiency:\")\n",
    "    print(f\"  Total Data Sent: {df_comm['bytes_sent'].sum() / 1e6:.2f} MB\")\n",
    "    print(f\"  Total Data Received: {df_comm['bytes_received'].sum() / 1e6:.2f} MB\")\n",
    "    print(f\"  Average per Round: {bytes_per_round.mean() / 1e6:.2f} MB sent\")\n",
    "    print(f\"  Average Communication Rounds: {comm_rounds.mean():.2f}\")\n",
    "else:\n",
    "    print(\"Communication efficiency metrics not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07b0cda",
   "metadata": {},
   "source": [
    "## 8. Convergence and Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce397f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'convergence' in dfs:\n",
    "    df_conv = dfs['convergence']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Convergence rate\n",
    "    axes[0, 0].plot(df_conv['round'], df_conv['accuracy_convergence_rate'], \n",
    "                   marker='o', linewidth=2, color='green')\n",
    "    axes[0, 0].axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "    axes[0, 0].set_xlabel('Round')\n",
    "    axes[0, 0].set_ylabel('Convergence Rate')\n",
    "    axes[0, 0].set_title('Accuracy Convergence Rate')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Client accuracy spread\n",
    "    axes[0, 1].fill_between(df_conv['round'], \n",
    "                            df_conv['client_accuracy_min'], \n",
    "                            df_conv['client_accuracy_max'], \n",
    "                            alpha=0.3, label='Min-Max Range')\n",
    "    axes[0, 1].plot(df_conv['round'], df_conv['client_accuracy_mean'], \n",
    "                   marker='o', linewidth=2, color='blue', label='Mean')\n",
    "    axes[0, 1].set_xlabel('Round')\n",
    "    axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "    axes[0, 1].set_title('Client Accuracy Spread Over Rounds')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Standard deviation (fairness indicator)\n",
    "    axes[1, 0].plot(df_conv['round'], df_conv['client_accuracy_std'], \n",
    "                   marker='o', linewidth=2, color='purple')\n",
    "    axes[1, 0].set_xlabel('Round')\n",
    "    axes[1, 0].set_ylabel('Standard Deviation (%)')\n",
    "    axes[1, 0].set_title('Client Accuracy Std Dev (Fairness Indicator)')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Stragglers detection\n",
    "    straggler_counts = df_conv.groupby('round')['stragglers_count'].first()\n",
    "    axes[1, 1].plot(straggler_counts.index, straggler_counts.values, \n",
    "                   marker='o', linewidth=2, color='red')\n",
    "    axes[1, 1].fill_between(straggler_counts.index, straggler_counts.values, \n",
    "                            alpha=0.3, color='red')\n",
    "    axes[1, 1].set_xlabel('Round')\n",
    "    axes[1, 1].set_ylabel('Number of Stragglers')\n",
    "    axes[1, 1].set_title('Straggler Detection Over Rounds')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / 'convergence_fairness.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nConvergence and Fairness:\")\n",
    "    print(f\"  Average Convergence Rate: {df_conv['accuracy_convergence_rate'].mean():.6f}\")\n",
    "    print(f\"  Final Fairness (Std Dev): {df_conv['client_accuracy_std'].iloc[-1]:.2f}%\")\n",
    "    print(f\"  Total Stragglers: {df_conv['stragglers_count'].sum():.0f}\")\n",
    "else:\n",
    "    print(\"Convergence metrics not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befc3a7f",
   "metadata": {},
   "source": [
    "## 9. Data Distribution Heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abecb6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'data_dist' in dfs:\n",
    "    df_dist = dfs['data_dist']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # 1. Heterogeneity scores\n",
    "    axes[0].bar(df_dist['client_id'], df_dist['data_heterogeneity_score'], \n",
    "               alpha=0.7, color='purple')\n",
    "    axes[0].axhline(df_dist['data_heterogeneity_score'].mean(), \n",
    "                   color='red', linestyle='--', linewidth=2, \n",
    "                   label=f\"Mean: {df_dist['data_heterogeneity_score'].mean():.4f}\")\n",
    "    axes[0].set_xlabel('Client ID')\n",
    "    axes[0].set_ylabel('Heterogeneity Score (KL Divergence)')\n",
    "    axes[0].set_title('Data Heterogeneity by Client')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 2. Sample distribution\n",
    "    axes[1].bar(df_dist['client_id'], df_dist['total_samples'], \n",
    "               alpha=0.7, color='teal')\n",
    "    axes[1].axhline(df_dist['total_samples'].mean(), \n",
    "                   color='red', linestyle='--', linewidth=2, \n",
    "                   label=f\"Mean: {df_dist['total_samples'].mean():.0f}\")\n",
    "    axes[1].set_xlabel('Client ID')\n",
    "    axes[1].set_ylabel('Total Samples')\n",
    "    axes[1].set_title('Dataset Size by Client')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / 'data_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nData Distribution Statistics:\")\n",
    "    print(f\"  Average Heterogeneity: {df_dist['data_heterogeneity_score'].mean():.4f}\")\n",
    "    print(f\"  Total Samples: {df_dist['total_samples'].sum()}\")\n",
    "    print(f\"  Imbalance Ratio: {df_dist['total_samples'].max() / df_dist['total_samples'].min():.2f}x\")\n",
    "else:\n",
    "    print(\"Data distribution metrics not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be0d024",
   "metadata": {},
   "source": [
    "## 10. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b3d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DECENTRALIZED FEDERATED LEARNING (P2P) - EXPERIMENT SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nðŸ“‹ CONFIGURATION\")\n",
    "print(\"-\" * 80)\n",
    "if config:\n",
    "    print(f\"  Mode: {config.get('type', 'decentralized')}\")\n",
    "    print(f\"  Mixing Method: {config.get('mixing_method', 'N/A')}\")\n",
    "    print(f\"  Clients: {config.get('num_clients', 'N/A')}\")\n",
    "    print(f\"  Rounds: {config.get('rounds', 'N/A')}\")\n",
    "    print(f\"  Epochs: {config.get('epochs', 'N/A')}\")\n",
    "    print(f\"  Dataset: {config.get('dataset', 'N/A')}\")\n",
    "    print(f\"  Model: {config.get('model', 'N/A')}\")\n",
    "    print(f\"  Partition: {config.get('partition', 'N/A')}\")\n",
    "\n",
    "if 'round_summary' in dfs:\n",
    "    df_summary = dfs['round_summary']\n",
    "    print(\"\\nðŸ“Š NETWORK PERFORMANCE\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"  Average Test Accuracy: {df_summary['avg_test_accuracy'].iloc[-1]:.2f}%\")\n",
    "    print(f\"  Average Test Loss: {df_summary['avg_test_loss'].iloc[-1]:.4f}\")\n",
    "    print(f\"  Best Average Accuracy: {df_summary['avg_test_accuracy'].max():.2f}%\")\n",
    "    print(f\"  Accuracy Range: [{df_summary['min_test_accuracy'].iloc[-1]:.2f}%, {df_summary['max_test_accuracy'].iloc[-1]:.2f}%]\")\n",
    "\n",
    "if 'propagation' in dfs:\n",
    "    df_prop = dfs['propagation']\n",
    "    print(\"\\nðŸ”„ GOSSIP PROPAGATION\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"  Total Messages: {df_prop['messages_sent'].sum():.0f}\")\n",
    "    print(f\"  Avg Messages per Round: {df_prop.groupby('round')['messages_sent'].sum().mean():.1f}\")\n",
    "    print(f\"  Avg Active Neighbors: {df_prop['active_neighbors'].mean():.2f}\")\n",
    "    print(f\"  Final Consensus Error: {df_prop.groupby('round')['consensus_error'].mean().iloc[-1]:.6f}\")\n",
    "    print(f\"  Avg Spectral Gap: {df_prop.groupby('round')['spectral_gap'].first().mean():.4f}\")\n",
    "\n",
    "if 'comm_eff' in dfs:\n",
    "    df_comm = dfs['comm_eff']\n",
    "    print(\"\\nðŸ“¡ COMMUNICATION\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"  Total Data Sent: {df_comm['bytes_sent'].sum() / 1e6:.2f} MB\")\n",
    "    print(f\"  Total Data Received: {df_comm['bytes_received'].sum() / 1e6:.2f} MB\")\n",
    "    print(f\"  Avg per Round: {df_comm.groupby('round')['bytes_sent'].sum().mean() / 1e6:.2f} MB\")\n",
    "\n",
    "if 'convergence' in dfs:\n",
    "    df_conv = dfs['convergence']\n",
    "    print(\"\\nðŸŽ¯ CONVERGENCE & FAIRNESS\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"  Total Stragglers: {df_conv['stragglers_count'].sum():.0f}\")\n",
    "    print(f\"  Avg Convergence Rate: {df_conv['accuracy_convergence_rate'].mean():.6f}\")\n",
    "    print(f\"  Final Fairness (Std): {df_conv['client_accuracy_std'].iloc[-1]:.2f}%\")\n",
    "\n",
    "if 'data_dist' in dfs:\n",
    "    df_dist = dfs['data_dist']\n",
    "    print(\"\\nðŸ“Š DATA DISTRIBUTION\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"  Avg Heterogeneity: {df_dist['data_heterogeneity_score'].mean():.4f}\")\n",
    "    print(f\"  Total Samples: {df_dist['total_samples'].sum()}\")\n",
    "    print(f\"  Imbalance Ratio: {df_dist['total_samples'].max() / df_dist['total_samples'].min():.2f}x\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Analysis complete! All plots saved to:\", plots_dir)\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
